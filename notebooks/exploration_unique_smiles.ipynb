{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "DATA_PATH = Path('../data/')\n",
    "SHRUNKEN_PATH = DATA_PATH / 'shrunken/'\n",
    "\n",
    "# check if global variables are defined\n",
    "if '_x_train_data' not in globals():\n",
    "    _x_train_data = None\n",
    "\n",
    "if '_x_bb' not in globals():\n",
    "    _x_bb = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def get_train_data() -> pq.ParquetFile:\n",
    "    global _x_train_data\n",
    "\n",
    "    if _x_train_data is not None:\n",
    "        return _x_train_data\n",
    "    \n",
    "    _x_train_data = pq.ParquetFile(SHRUNKEN_PATH / 'train.parquet')\n",
    "    return _x_train_data\n",
    "\n",
    "def get_train_building_blocks() -> dict[str, pq.ParquetFile]:\n",
    "\n",
    "    return {\n",
    "        \"bb1\": pq.ParquetFile(SHRUNKEN_PATH / 'train_dicts' / 'BBs_dict_reverse_1'),\n",
    "        \"bb2\": pq.ParquetFile(SHRUNKEN_PATH / 'train_dicts' / 'BBs_dict_reverse_2'),\n",
    "        \"bb3\": pq.ParquetFile(SHRUNKEN_PATH / 'train_dicts' / 'BBs_dict_reverse_3'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BRD4: 940, HSA: 940, SEH: 940, NONE: 940: 100%|██████████| 94/94 [00:21<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = get_train_data()\n",
    "print(f\"Groups: {data.num_row_groups}\")\n",
    "\n",
    "MAX_MOLS_PER_GROUP = 10\n",
    "\n",
    "smiles_bind_brd4: list[list[str]] = []\n",
    "smiles_bind_brd4_cnt = 0\n",
    "smiles_bind_hsa: list[list[str]]= []\n",
    "smiles_bind_hsa_cnt = 0\n",
    "smiles_bind_seh: list[list[str]] = []\n",
    "smiles_bind_seh_cnt = 0\n",
    "smiles_bind_none: list[list[str]] = []\n",
    "smiles_bind_none_cnt = 0\n",
    "\n",
    "def update_pbar_desc(pbar: tqdm):\n",
    "    desc = f\"BRD4: {smiles_bind_brd4_cnt}, HSA: {smiles_bind_hsa_cnt}, SEH: {smiles_bind_seh_cnt}, NONE: {smiles_bind_none_cnt}\"\n",
    "    pbar.set_description(desc)\n",
    "\n",
    "pbar = tqdm(range(data.num_row_groups))\n",
    "for group_idx in pbar:\n",
    "    group = data.read_row_group(group_idx)\n",
    "    smiles_bind_brd4.append([])\n",
    "    smiles_bind_hsa.append([])\n",
    "    smiles_bind_seh.append([])\n",
    "    smiles_bind_none.append([])\n",
    "\n",
    "    for row_idx in range(group.num_rows):\n",
    "        mol_smiles = group[3][row_idx]\n",
    "        binds_brd4 = True if group[4][row_idx].as_py() == 1 else False\n",
    "        binds_hsa = True if group[5][row_idx].as_py() == 1 else False\n",
    "        binds_seh = True if group[6][row_idx].as_py() == 1 else False\n",
    "        \n",
    "        if binds_brd4 and len(smiles_bind_brd4[group_idx]) < MAX_MOLS_PER_GROUP:\n",
    "            smiles_bind_brd4[group_idx].append(str(mol_smiles))\n",
    "            smiles_bind_brd4_cnt += 1\n",
    "            update_pbar_desc(pbar)\n",
    "        if binds_hsa and len(smiles_bind_hsa[group_idx]) < MAX_MOLS_PER_GROUP:\n",
    "            smiles_bind_hsa[group_idx].append(str(mol_smiles))\n",
    "            smiles_bind_hsa_cnt += 1\n",
    "            update_pbar_desc(pbar)\n",
    "        if binds_seh and len(smiles_bind_seh[group_idx]) < MAX_MOLS_PER_GROUP:\n",
    "            smiles_bind_seh[group_idx].append(str(mol_smiles))\n",
    "            smiles_bind_seh_cnt += 1\n",
    "            update_pbar_desc(pbar)\n",
    "        if not binds_brd4 and not binds_hsa and not binds_seh and len(smiles_bind_none[group_idx]) < MAX_MOLS_PER_GROUP:\n",
    "            smiles_bind_none[group_idx].append(str(mol_smiles))\n",
    "            smiles_bind_none_cnt += 1\n",
    "            update_pbar_desc(pbar)\n",
    "\n",
    "        if (len(smiles_bind_brd4[group_idx]) == MAX_MOLS_PER_GROUP and\n",
    "            len(smiles_bind_hsa[group_idx]) == MAX_MOLS_PER_GROUP and\n",
    "            len(smiles_bind_seh[group_idx]) == MAX_MOLS_PER_GROUP and\n",
    "            len(smiles_bind_none[group_idx]) == MAX_MOLS_PER_GROUP):\n",
    "            break\n",
    "        \n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRD4\n",
      "['CC12CCC(CNc3nc(NCc4ccc(CN5CCCC5=O)cc4)nc(Nc4c(C(=O)N[Dy])ccc5ccccc45)n3)(C1)OC2',\n",
      " 'Cn1cc(Nc2nc(Nc3ncncc3C#N)nc(N[C@H](CC(=O)N[Dy])c3cccs3)n2)ccc1=O',\n",
      " 'CC(=O)c1ccc(Nc2nc(NCCS(=O)(=O)Nc3ccccc3)nc(Nc3ccc(C(=O)N[Dy])nc3)n2)c(F)c1']\n",
      "HSA\n",
      "['O=C(N[Dy])C1c2ccccc2CN1c1nc(NCCS(=O)(=O)C2CCOCC2)nc(Nc2ncnc3[nH]cnc23)n1',\n",
      " 'CS(=O)(=O)c1cccc(Nc2nc(Nc3cc(Cl)nc(Cl)c3[N+](=O)[O-])nc(N[C@@H](Cc3cccnc3)C(=O)N[Dy])n2)c1',\n",
      " 'CCn1cc(Nc2nc(Nc3ccc4c(c3)COC4=O)nc(N[C@@H](CC(=O)N[Dy])Cc3cccs3)n2)c(C)n1']\n",
      "SEH\n",
      "['Cc1cc2cc(CNc3nc(NCc4cccnc4OC(F)F)nc(N[C@H](Cc4cn(C)c5ccccc45)C(=O)N[Dy])n3)ccc2[nH]1',\n",
      " 'CCOC(=O)c1ncccc1Nc1nc(Nc2cccc(-n3cncn3)c2)nc(Nc2nc3cc(C(=O)N[Dy])ccc3[nH]2)n1',\n",
      " 'COC(=O)c1cncc(Nc2nc(NCC3CCCn4ccnc43)nc(Nc3c(Br)cccc3C(=O)N[Dy])n2)c1']\n",
      "NONE\n",
      "['CC(C)(C)OC(=O)n1ncc2cc(Nc3nc(NCc4nnc(-c5ccncc5)[nH]4)nc(N[C@H](Cc4ccc(Cl)cc4)C(=O)N[Dy])n3)ccc21',\n",
      " 'O=C(N[Dy])c1cc(Nc2nc(NC[C@@H]3C[C@@H]4O[C@H]3[C@H]3C[C@H]34)nc(NCC3(N4CCOCC4)CC3)n2)ccc1[N+](=O)[O-]',\n",
      " 'C#Cc1cccc(Nc2nc(Nc3nc(C(F)(F)F)c(C(=O)N[Dy])s3)nc(Nc3c(C)cc(Cl)nc3Cl)n2)c1']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "smiles_bind_brd4 = [x for group in smiles_bind_brd4 for x in group]\n",
    "smiles_bind_hsa = [x for group in smiles_bind_hsa for x in group]\n",
    "smiles_bind_seh = [x for group in smiles_bind_seh for x in group]\n",
    "smiles_bind_none = [x for group in smiles_bind_none for x in group]\n",
    "\n",
    "# Randomly sample 3 from each group\n",
    "smiles_bind_brd4 = shuffle(smiles_bind_brd4)[:3]\n",
    "smiles_bind_hsa = shuffle(smiles_bind_hsa)[:3]\n",
    "smiles_bind_seh = shuffle(smiles_bind_seh)[:3]\n",
    "smiles_bind_none = shuffle(smiles_bind_none)[:3]\n",
    "\n",
    "\n",
    "print(\"BRD4\")\n",
    "pprint(smiles_bind_brd4)\n",
    "\n",
    "print(\"HSA\")\n",
    "pprint(smiles_bind_hsa)\n",
    "\n",
    "print(\"SEH\")\n",
    "pprint(smiles_bind_seh)\n",
    "\n",
    "print(\"NONE\")\n",
    "pprint(smiles_bind_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(smiles_bind_brd4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
