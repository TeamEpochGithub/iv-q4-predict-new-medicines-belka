defaults:
  - pipeline/default@_here_
  - _self_

x_sys:
  steps: []
y_sys:
  steps: []

train_sys:
  steps:
    # Pretrain the model
    - _target_: src.modules.training.graph_trainer.GraphTrainer
      model_name: GCNEdgesPretrain

      model:
        _target_: src.modules.training.models.gcn_edge_features.GCNWithEdgeFeatures
        n_classes: 3
        num_node_features: 22
        num_edge_features: 2
      optimizer: # Partially instantiate optimizer, so model parameters can be linked at runtime
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.AdamW
        lr: 0.001
      criterion:
        _target_: torch.nn.BCEWithLogitsLoss
      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: timm.scheduler.cosine_lr.CosineLRScheduler
        t_initial: 40
        cycle_mul: 1
        cycle_decay: 1
        cycle_limit: 1
        warmup_t: 1
        warmup_lr_init: 1e-5
      dataloader_args:
        num_workers: 26
        prefetch_factor: 4
        persistent_workers: true

      epochs: 10
      patience: 3
      batch_size: 512
      sample_size: 100_000

      n_folds: 5

      dataset:
        _target_: src.modules.training.datasets.graph_dataset.GraphDataset
        retrieval: [ "SMILES_MOL" ]
        steps:
          - _target_: src.modules.training.dataset_steps.graphs.smiles_to_graph.SmilesToGraph
            use_atom_chem_features: true
            use_atom_pharmacophore_features: true
            use_bond_features: true


    # Train the model
    - _target_: src.modules.training.graph_trainer.GraphTrainer
      model_name: GCNEdges

      model:
        _target_: src.modules.training.models.gcn_edge_features.GCNWithEdgeFeatures
        n_classes: 3
        num_node_features: 22
        num_edge_features: 2
      optimizer: # Partially instantiate optimizer, so model parameters can be linked at runtime
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.AdamW
        lr: 0.001
      criterion:
        _target_: torch.nn.BCEWithLogitsLoss
      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: timm.scheduler.cosine_lr.CosineLRScheduler
        t_initial: 40
        cycle_mul: 1
        cycle_decay: 1
        cycle_limit: 1
        warmup_t: 1
        warmup_lr_init: 1e-5
      dataloader_args:
        num_workers: 26
        prefetch_factor: 4
        persistent_workers: true

      epochs: 10
      patience: 3
      batch_size: 512

      n_folds: 5

      dataset:
        _target_: src.modules.training.datasets.graph_dataset.GraphDataset
        retrieval: [ "SMILES_MOL" ]
        steps:
          - _target_: src.modules.training.dataset_steps.graphs.smiles_to_graph.SmilesToGraph
            use_atom_chem_features: true
            use_atom_pharmacophore_features: true
            use_bond_features: true

    # Create prediction statistics
    - _target_: src.modules.training.analysis.prediction_statistics.PredictionStatistics

pred_sys:
  steps:
    - _target_: src.modules.transformation.sigmoid.Sigmoid

label_sys:
  steps: []
