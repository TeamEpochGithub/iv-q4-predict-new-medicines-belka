defaults:
  - pipeline/default@_here_
  - _self_

x_sys:
  steps: []

y_sys:
  steps: []

train_sys:
  steps:
    - _target_: src.modules.training.trainers.two_headed_trainer.TwoHeadedTrainer
      model_name: TwoHeadedCNN1D
      loss1_weight: 10
      model:
        _target_: src.modules.training.models.multi_headed_cnn1d.TwoHeadedCNN1D
        n_classes: 3
        n_bits: 32
        num_embeddings: 5000
        hidden_dim: 128
        filters: 64
      criterion:
        _target_: torch.nn.BCEWithLogitsLoss
        # _target_: src.modules.loss.focal_loss.FocalLoss
      optimizer: # Partially instantiate optimizer, so model parameters can be linked at runtime
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.Adam
        lr: 0.001
      epochs: 10
      batch_size: 1027
      patience: 5
      dataset:
        _target_: src.modules.training.datasets.main_dataset.MainDataset
        retrieval: ["SMILES_MOL"]
        steps:
          - _target_: src.modules.training.dataset_steps.embeddings.ecfp.ECFPLabel
            bits: 32
          - _target_: src.modules.training.dataset_steps.smiles.tokenize_molecule.TokenizeMolecule
            tokenizer_name: "samples_100M_window_4"
            padding_size: 150
      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: timm.scheduler.cosine_lr.CosineLRScheduler
        t_initial: 40
        cycle_mul: 1
        cycle_decay: 1
        cycle_limit: 1
        warmup_t: 4
        warmup_lr_init: 2e-07
      n_folds: 5
      x_tensor_type: int
      dataloader_args:
        num_workers: 28
        prefetch_factor: 5
        persistent_workers: true
    - _target_: src.modules.training.analysis.prediction_statistics.PredictionStatistics

pred_sys:
  steps:
    - _target_: src.modules.transformation.sigmoid.Sigmoid

label_sys:
  steps: []